
The following have been reloaded with a version change:
  1) CUDA/9.0.176-GCC-6.4.0-2.28 => CUDA/9.2.88-GCC-7.3.0-2.30
  2) GCC/6.4.0-2.28 => GCC/7.3.0-2.30
  3) GCCcore/6.4.0 => GCCcore/7.3.0
  4) binutils/2.28-GCCcore-6.4.0 => binutils/2.30-GCCcore-7.3.0

/home/smolima2/nlp/small_pretrained_lms/models/structure.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  nn.utils.clip_grad_norm(self.parameters(), tconfig.clip_grad)
Network structure: BertModel, with parameters: 702,400
BertModel(
  (embeddings): BertEmbeddings(
    (word_embeddings): Embedding(10000, 64, padding_idx=0)
    (position_embeddings): Embedding(512, 64)
    (token_type_embeddings): Embedding(2, 64)
    (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): BertEncoder(
    (layer): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=64, out_features=64, bias=True)
            (key): Linear(in_features=64, out_features=64, bias=True)
            (value): Linear(in_features=64, out_features=64, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=64, out_features=64, bias=True)
            (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=64, out_features=64, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (pooler): BertPooler(
    (dense): Linear(in_features=64, out_features=64, bias=True)
    (activation): Tanh()
  )
)
/home/smolima2/nlp/small_pretrained_lms/../data/semeval/downstream/EmoContext/vocab
loading subword model : /home/smolima2/nlp/small_pretrained_lms/../data/semeval/downstream/EmoContext/vocab/EmoContext.bpe.model
reloaded embedder
reloaded encoder
reloaded classifier
4
2755
/home/smolima2/nlp/small_pretrained_lms/../data/semeval/downstream/EmoContext/vocab
loading subword model : /home/smolima2/nlp/small_pretrained_lms/../data/semeval/downstream/EmoContext/vocab/EmoContext.bpe.model
PROGRESS (encoding train): 0.00%
PROGRESS (encoding train): 10.61%
PROGRESS (encoding train): 21.22%
PROGRESS (encoding train): 31.83%
PROGRESS (encoding train): 42.44%
PROGRESS (encoding train): 53.05%
PROGRESS (encoding train): 63.66%
PROGRESS (encoding train): 74.27%
PROGRESS (encoding train): 84.88%
PROGRESS (encoding train): 95.49%
PROGRESS (encoding dev): 0.00%
PROGRESS (encoding test): 0.00%
PROGRESS (encoding test): 58.09%
train results:
{'EmoContext': None}
test_results:
{'EmoContext': {'devacc': 0.8925589836660617, 'acc': 0.8978035941187148, 'devloss': 0.3229302167892456, 'loss': 0.32754236459732056, 'devf1': 0.8925589836660617, 'f1': 0.8978035941187148, 'ndev': 2755, 'ntest': 5509}}
